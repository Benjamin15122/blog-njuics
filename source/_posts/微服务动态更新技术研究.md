---
title: 微服务动态更新技术研究
date: 2018-07-27 17:33:11
tags:
---
### 微服务与动态更新
相比较与传统庞大的单体应用，微服务选择了将应用按功能划分成若干微服务，每个微服务运行在各自独立的进程中，甚至可以使用不同的编程语言来实现相应功能。正是因为这种松耦合性和可扩展性，微服务架构开始在应用开发中占据主导地位。

![Microservice](/images/microservice.png)

互联网应用在其提供服务的生命周期中，由于用户需求、漏洞修复、数据迁移等多种因素，总是需要周期性地进行版本的更新。传统的应用更新方式可称为静态更新，是在停止应用业务的基础上，后台对该应用进行更新并重启。而随着互联网逐渐渗透到我们生活的方方面面，无论是从经济利益方面还是从更重要的生命财产等方面进行考虑，传统的更新方式都无法胜任，因此需要对应用进行动态更新。

动态更新最本质的要求便是在应用能够在正常地处理外来请求的基础上，正确地对应用进行版本的更新。动态更新一方面保证了在更新过程中系统的可用性，另一方面使得程序的维护成本下降，减轻了软件公司繁琐的维护工作，提高了工作效率。

如果需要对微服务架构中的服务进行动态更新，则需要重点考虑在新版本的微服务应如何加入系统，以及加入之后整个系统要依据怎样的规则来对不同版本的微服务进行选择，才能保证整个系统在该服务更新过程时的可用性和更新前后系统的一致性。


### 相关技术的研究
在动态更新的过程中，如何对新版本的微服务进行上线部署是一个关键的步骤。目前常用的不需要停机即可完成部署的技术，主要有以下三种：

* 蓝绿部署(Blue/Green Deployment)：蓝绿部署在微服务存在更新版本时，不停止老版本的工作并且将所有的请求都转发给老版本进行处理，与此同时部署新版本并进行自主的测试，若测试通过则将请求从老版本转到新版本进行处理。经过一段时间的试用期后，若新版本未出现问题，则对老版本进行更新或者直接删除老版本以释放资源。蓝绿部署的过程中微服务始终在线处理请求，并且新版本的上线部署不会影响老版本的状态或者修改老版本的内容。这样部署过程的风险较低，同时只要老版本的资源不被删除或者修改，理论上微服务可以在任何时间回滚至原先的版本。<br />


* 滚动发布(Rolling Update)：滚动发布在微服务存在更新版本时，一般是取出若干比例的微服务实例，将他们下线停止服务并执行更新操作，然后重新上线提供服务。通过不断地取出未被更新的微服务实例进行更新，最终将系统中所有的微服务实例都进行更新且上线提供服务。相对于蓝绿部署，滚动发布的优势在于节约了资源，它无需运行两个版本、两倍的微服务实例。但缺点也显而易见，系统中没有一个环境是确定有效的，一旦更新的版本出现任何问题需要回滚时，将会难以实现，同时短暂出现的新老版本不一致问题可能也无法满足需求。<br />


* 灰度发布/金丝雀部署(Canary Deployment)：灰度发布是指在黑与白之间，能够平滑过渡的一种发布方式，而金丝雀部署是灰度发布的一种具体部署方式。与蓝绿部署类似，金丝雀部署在原有版本可用的情况下同时会部署一个新的版本。不同的是金丝雀部署可由用户设置路由权重，决定使用老版本和新版本服务的比例，若用户使用新版本的反馈良好，则对老版本进行升级，从而达到动态调整不同的权重来进行新老版本的验证的目的。这样保证了系统整体运行的稳定性，且在早期便可以发现、调整问题，保证错误不会影响到更多的服务。


### 系统的实现
#### 模拟数据库读取系统
此系统基于下图所展示的各个构件之间的相互依赖关系，具体利用Spring Cloud框架设计实现出相应的微服务功能，来对数据库的读取加以模拟：Portal微服务是系统暴露给用户的入口微服务，用户希望通过调用Portal微服务所提供的接口来获得数据库中的数据信息。在Portal微服务中，它首先通过调用Auth微服务来得到秘钥信息，然后调用Porc微服务并传递秘钥信息，而Proc微服务利用所接收到的秘钥信息再次调用Auth微服务来进行身份的验证，只有通过验证，Proc微服务才会调用DB微服务得到数据库中的结果并将结果返回给Portal，然后由Portal微服务将最终的结果展示给用户。

![Example System](/images/example-system.png)

显然在上述的调用过程中，两次调用Auth微服务的版本一致性将影响到整个系统的一致性。因此系统的设计实现应重点考虑：Auth微服务应在何时进行新版本的上线部署；正在运行中的系统面对着可能存在的微服务的多版本问题应基于怎样的策略进行选择。

为解决上述问题，我们提出了面向微服务静止态的动态更新技术，一方面具体说明了静止态的定义及其作为微服务动态更新条件的正确性，另一方面介绍了系统在面对微服务的多版本问题时所采用的动态调用策略。具体而言：

1. 我们首先提出微服务静止态的定义。当某个微服务实例满足以下条件时，我们可以称其处于静止态：

	> 该微服务实例在本次完整的调用链中要么还从未被调用过，要么虽然被调用过，但它之前被调用所返回的结果不会对后续的请求产生影响

 <br> 显然，静止态的定义通过对某个微服务实例先前是否被调用过进行判断，保证了该微服务实例处于一种未污染状态；而如果该微服务实例的返回结果会对未来的调用产生影响，下一小节所提出的选择策略将确保系统两次调用的微服务实例版本保持一致。
 
 上述两个部分的讨论说明了我们对处于静止态的微服务所进行的更新操作是一次安全、无污染的操作，不会因此操作而影响到整个系统运行的一致性和稳定性，从而证明了静止态作为微服务动态更新条件的充分性。
 
 在具体实现时主要需要标记该微服务实例是否被调用过，因此为每一个微服务实例添加一个集合。当该微服务实例被调用时，往集合中添加一个标记。若此微服务实例的返回结果不会对后续结果产生影响，那么我们只需在此次调用结束后将集合中的标记删去即可；若其返回结果将会一直影响系统的此次请求调用链，那么集合中的标记只能在系统处理此次请求的过程中，最后一次调用该微服务实例结束后删去。这样某个微服务实例处于静止态，当且仅当其所拥有的集合为空。
 
 ```java
 //调用开始
collection.add(one);
//调用结束
collection.remove(one);
//静止态判定
if (collection.isEmpty())
	return true;
 ```
 
2. 基于前一小节对于微服务静止态定义的讨论，在系统处理请求时遇到的微服务多版本共存的情况，我们的选择策略为：
	> 若该微服务在此次请求中还从未被调用过，或者虽然被调用过，但它之前被调用所返回的结果不会对当前及后续的请求产生影响，那么系统将会选择最新的版本进行调用。   
	
	> 若该微服务之前被调用过，且被调用所返回的结果将会影响到当前的请求，那么系统当前所调用的版本应与该微服务之前被调用过的版本保持一致。
	
 <br> 具体实现时主要对微服务实例返回结果的两种情况进行讨论：若该微服务在此次请求中还从未被调用过，或者虽然被调用过，但它之前被调用所返回的结果不会对当前及后续的请求产生影响，那么系统将会选择最新的版本进行调用；若为另一种情况，我们选择将该微服务实例的对应端口号伴随着调用链一直传递下去，当需要调用该微服务实例时，直接利用端口号进行快速查找调用。在请求最后一次调用该微服务实例结束后删去即可。
	
 ```java
 //Portal端调用Auth微服务
 http://auth-service/auth/portal/newestAuthPort/
 //Proc端调用Auth微服务
 http://auth-service/auth/proc/formerAuthPort/
 ```
 在对选择策略的正确性和系统更新前后的一致性进行验证实验时，我们在Portal得到Auth的返回结果而未调用Proc时，使Portal微服务休眠一段适当长的时间，此时对新版本的Auth微服务进行上线部署(不同版本的微服务)，从而成功地模拟出系统在运行过程中所遇到的多版本微服务的选择问题。
 
 ![前一次调用](/images/former-auth.png)
 
 ![加入新版本Auth后的Eureka](/images/new-eureka.png)
 
 ![后一次调用](/images/latter-auth.png)
 
 可以看出，我们的选择策略确保了系统在处理请求时不会因前后某一微服务的调用版本不同而出现系统不一致的问题，在此基础上，策略要求系统尽可能地对新版本的微服务进行调用，这样使得系统所返回的结果具有较好的时效性。
	
利用上述的面向微服务静止态的动态更新技术，并辅以其它的辅助模块，最终实现出一套模拟数据库读取的动态更新系统。此系统为用户提供了可对微服务进行更新操作的同时，保证了各个微服务在进行动态更新的过程中整个系统的可用性。并且系统在微服务更新前后的一致性也可以很好地通过修改后的Zipkin追踪系统来进行验证。
 	
#### 台风系统
实现好的台风系统中，前端包括了监控预警系统api-gateway和动态效果演示系统inap，后端则包括了台风typhoon、天气weather、水文hydrology等微服务为前端提供数据上的支持。系统在工作时，以监控预警系统为中心，周期性地向台风微服务发送请求，读取当前台风所在位置及相应的风速、风力等基本信息，对左上角图表进行绘制；然后依次对天气和水文微服务进行调用，而天气和水文在处理请求时会再次向台风微服务发送请求，并利用当前台风所在的位置信息来对台风是否会对周围产生影响进行判断，进一步来生成预警信息和降雨水位信息。

![台风系统](/images/typhoon.png)

台风系统的另一个前端动态效果演示系统inap只需周期性地对上述调用过程中的依赖关系进行绘制，展示出所有的微服务列表，并调用相关API得到对应微服务的服务版本、软件定义和度量信息。

不同于之前模拟数据库读取系统的是，台风系统的所有微服务都进一步封装成docker容器，并利用现有的marathon框架将微服务部署到集群上面去运行。可以看到每个微服务的版本信息按时间的先后次序形成树状，树上的每个节点便对应着微服务的一个版本。当我们点击了树上其它节点，想要进行版本的更新或者切换时，系统首先会到镜像仓库中取出对应版本的镜像，然后利用marathon所提供的API接口，基于先前所得到的镜像上线一个新的微服务容器。一旦新的容器可以正常地提供服务，系统对于此微服务的调用请求便从旧的容器转交给新的容器进行处理，而旧的容器则停止工作。

虽然上述的版本更新过程较为方便简捷，但一个比较关键的问题是：此次更新过程无法保证整个系统运行时的一致性。针对台风这个微服务的更新过程来进行分析，我们可以发现：如果监控预警系统对台风微服务进行了调用并得到了台风相对应的位置信息，而此时新版本的台风微服务上线，那么天气微服务和水文微服务所调用将是新版本的台风微服务。新旧版本台风微服务的调用所返回的结果如何能够保证整个系统的一致性，成为我们对台风微服务进行动态更新所需要解决的首要问题。

为解决此问题，我具体提出了两种实验方案，并分别进行了设计实现：

1. 如前所述，台风微服务在某个位置上的信息将会被监控预警系统、天气和水文三个微服务进行调用，而一旦在这个过程中台风微服务发生版本变更，系统的一致性便无法保证。因此，我选择扩大这三个微服务调用台风微服务的周期，从而使得台风微服务在处理完上一个位置信息且未接收到下一个位置信息的请求的这段时间增长。与此同时，在台风微服务中添加相应的指示变量，用于判断台风微服务当前是否处于某个位置的请求处理链之中。

 此时，台风微服务的动态更新逻辑过程便有所不同：用户在点击树节点进行版本的更新或者切换时，首先会向台风微服务的updateRequest接口发出请求，此接口在收到请求之后对新增的指示变量进行判断，若通过则直接返回true结果，否则此次请求将会短暂地进行休眠，结束后继续进行判断，直到通过为止。在接收到updateRequest接口所返回的结果之后，我们便可以确定此时的台风微服务不处于任一条请求的处理链之中，因此我们便可以对新的台风微服务进行上线部署，且系统的一致性也能够得到保证。
 
 此种方案虽然在保证系统一致性的前提下成功地对台风微服务进行了动态更新，但相对应所付出的代价是前端的监控预警系统可能需要等待较长的时间才能得到台风在某个位置上的全部信息。此种方案在本地进行了成功的实验，但未具体应用到集群中。
 
2.  考虑到台风微服务中所返回的位置信息是经由json文件读出，而json文件在不同版本的微服务之间是不会改变的。因此，我选择将台风微服务中与台风位置相关联的全局变量存储到文件，而新版本的台风微服务在上线后利用该文件进行当前台风位置信息的重构，这样一来虽然处于某个位置的请求处理链之中的台风微服务进行了版本的更新或者切换，但系统的一致性仍然能够得到保证。同时，marathon框架对于两个容器之间进行切换的条件判断，确保了旧容器一定是在被调用完之后才被替换，从而进一步保证了台风微服务动态更新的过程中整个系统的可用性。
 
 此时，台风微服务的动态更新逻辑过程变为：用户可在需要的任一时刻点击树节点进行版本的更新或者切换，而且无需向台风微服务发送消息或者进行条件的判断。只需要后台为我们将新版本的台风微服务打包成镜像并上线部署新容器到marathon中，等到旧版本容器处理完本次的调用工作后，marathon框架会向旧容器发送SIGTERM信号，告知其即将被关闭。而接收到信号的旧版本台风微服务便将全局变量存储到文件中，供新容器进行读取。
 
 此方案的优点在于利用了台风位置的持久性和marathon框架本身所提供的便利性，使得不需要进行过多的条件判断和较长的等待时间便可以顺利完成台风微服务的动态更新，且不会影响整个系统的一致性和可用性。但此方案仅适用于此台风微服务所处的场景，依赖的外部条件较多。目前已经在集群中成功接收到SIGTERM信号，读写文件还需要进一步的测试。
